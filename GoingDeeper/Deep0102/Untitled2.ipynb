{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "833a95a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Size: 150001\n",
      "Example:\n",
      ">> id\tdocument\tlabel\n",
      ">> 3989148\t약탈자를 위한 변명, 이라. 저놈들은 착한놈들 절대 아닌걸요.\t1\n",
      ">> 4805788\t이 영화가 왜 이렇게 저평가 받는지 모르겠다\t1\n",
      ">> 8317483\t백봉기 언제나오나요?\t1\n",
      ">> 9801316\t아햏햏 아햏햏 아햏햏.\t1\n",
      "Data Size: 150001\n",
      "문장의 최단 길이: 8\n",
      "문장의 최장 길이: 168\n",
      "문장의 평균 길이: 45\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp --model_prefix=korean_spm --vocab_size=8000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
      "  input_format: \n",
      "  model_prefix: korean_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 141126 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=4316373\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1727\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 141126 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 253868 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 141126\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 292208\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 292208 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=130922 obj=15.34 num_tokens=686421 num_tokens/piece=5.24298\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=121347 obj=14.2801 num_tokens=690873 num_tokens/piece=5.69337\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=90965 obj=14.3934 num_tokens=720954 num_tokens/piece=7.92562\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=90813 obj=14.3355 num_tokens=721466 num_tokens/piece=7.94452\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=68105 obj=14.5911 num_tokens=758655 num_tokens/piece=11.1395\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=68096 obj=14.527 num_tokens=758812 num_tokens/piece=11.1433\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=51072 obj=14.801 num_tokens=794387 num_tokens/piece=15.5543\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=51072 obj=14.7374 num_tokens=794389 num_tokens/piece=15.5543\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=38304 obj=15.0484 num_tokens=832791 num_tokens/piece=21.7416\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=38304 obj=14.9818 num_tokens=832793 num_tokens/piece=21.7417\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=28728 obj=15.3246 num_tokens=872073 num_tokens/piece=30.3562\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=28728 obj=15.2553 num_tokens=872081 num_tokens/piece=30.3565\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=21546 obj=15.6351 num_tokens=912697 num_tokens/piece=42.3604\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=21546 obj=15.5601 num_tokens=912701 num_tokens/piece=42.3606\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=16159 obj=15.9664 num_tokens=955037 num_tokens/piece=59.1025\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=16159 obj=15.8825 num_tokens=955042 num_tokens/piece=59.1028\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=12119 obj=16.3335 num_tokens=1000433 num_tokens/piece=82.5508\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=12119 obj=16.2283 num_tokens=1000498 num_tokens/piece=82.5562\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=9089 obj=16.7266 num_tokens=1049903 num_tokens/piece=115.514\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=9089 obj=16.6184 num_tokens=1049963 num_tokens/piece=115.52\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=16.6814 num_tokens=1056286 num_tokens/piece=120.032\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=16.6675 num_tokens=1056284 num_tokens/piece=120.032\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: korean_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korean_spm.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 375224 May  9 07:09 korean_spm.model\n",
      "-rw-r--r-- 1 root root 144684 May  9 07:09 korean_spm.vocab\n",
      "[1533, 9, 406, 15, 1388, 9, 138, 17, 4]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 128)         1024000   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, None, 64)          49408     \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,086,913\n",
      "Trainable params: 1,086,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1765/1765 [==============================] - 19s 9ms/step - loss: 0.6933 - accuracy: 0.4977 - val_loss: 0.6931 - val_accuracy: 0.5006\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69315, saving model to ./best_sentiment_model.h5\n",
      "Epoch 2/20\n",
      "1765/1765 [==============================] - 16s 9ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6932 - val_accuracy: 0.5006\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.69315\n",
      "Epoch 3/20\n",
      "1765/1765 [==============================] - 16s 9ms/step - loss: 0.6932 - accuracy: 0.5018 - val_loss: 0.6932 - val_accuracy: 0.5006\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69315\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 4/20\n",
      " 841/1765 [=============>................] - ETA: 7s - loss: 0.6932 - accuracy: 0.4994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14220/523681495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    201\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import konlpy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path_to_file = os.getenv('HOME')+'/aiffel/AIFFEL_quest_rs/GoingDeeper/Deep0102/data/ratings_train.txt'\n",
    "\n",
    "with open(path_to_file, \"r\") as f:\n",
    "    train = f.read().splitlines()\n",
    "\n",
    "print(\"Data Size:\", len(train))\n",
    "\n",
    "print(\"Example:\")\n",
    "for sen in train[0:100][::20]: print(\">>\", sen)\n",
    "\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "cleaned_corpus = sorted(set(train))  # set를 사용해서 중복을 제거합니다.\n",
    "print(\"Data Size:\", len(cleaned_corpus))\n",
    "\n",
    "for sen in cleaned_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(cleaned_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in cleaned_corpus:   # 중복이 제거된 코퍼스 기준\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()\n",
    "\n",
    "max_len = 100\n",
    "min_len = 0\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_corpus = [s for s in cleaned_corpus if (len(s) < max_len) & (len(s) >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려봅니다.\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "for sen in filtered_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()\n",
    "\n",
    "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer\n",
    "\n",
    "import sentencepiece as spm\n",
    "import os\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/korean-english-park.train.ko.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "# 여기서 전체 학습 데이터를 사용하도록 수정\n",
    "train_path = os.getenv('HOME') + '/aiffel/AIFFEL_quest_rs/GoingDeeper/Deep0102/data/ratings_train.txt'\n",
    "test_path = os.getenv('HOME') + '/aiffel/AIFFEL_quest_rs/GoingDeeper/Deep0102/data/ratings_test.txt'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "train_df = pd.read_csv(train_path, sep='\\t').dropna()\n",
    "test_df = pd.read_csv(test_path, sep='\\t').dropna()\n",
    "\n",
    "# Extract texts and labels\n",
    "train_sentences = train_df['document'].astype(str).tolist()\n",
    "train_labels = train_df['label'].astype(int).tolist()\n",
    "\n",
    "test_sentences = test_df['document'].astype(str).tolist()\n",
    "test_labels = test_df['label'].astype(int).tolist()\n",
    "\n",
    "# Optional: 문장 길이 제한\n",
    "max_len = 100\n",
    "train_data = [(s, l) for s, l in zip(train_sentences, train_labels) if len(s) < max_len]\n",
    "test_data = [(s, l) for s, l in zip(test_sentences, test_labels) if len(s) < max_len]\n",
    "\n",
    "train_sentences, train_labels = zip(*train_data)\n",
    "test_sentences, test_labels = zip(*test_data)\n",
    "\n",
    "# SentencePiece 모델 훈련을 위한 임시 파일 생성 (실제 학습 데이터 사용)\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in train_sentences:   # 실제 훈련에 사용될 데이터로 모델 학습\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "#위 Train에서  --model_type = unigram이 디폴트 적용되어 있습니다. --model_type = bpe로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*\n",
    "\n",
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))\n",
    "\n",
    "# 토크나이징 함수\n",
    "def tokenize_with_sp(sp, corpus):\n",
    "    tensor = [sp.EncodeAsIds(sen) for sen in corpus]\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    return tensor\n",
    "\n",
    "X_train = tokenize_with_sp(s, train_sentences)\n",
    "X_test = tokenize_with_sp(s, test_sentences)\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "vocab_size = len(s)  # SentencePiece vocab size\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# 모델 개선: Dropout 추가 및 Embedding 크기 조정\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 128),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),  # 과적합 방지\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# 모델 저장 경로\n",
    "checkpoint_path = './best_sentiment_model.h5'\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',     # 검증 손실 기준\n",
    "    patience=5,             # 5 epoch 이상 향상 없으면 중단\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks = [early_stop, checkpoint]\n",
    "\n",
    "# 배치 크기 줄이기, 학습률 감소 콜백 추가\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=0.0001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks.append(reduce_lr)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=64,  # 배치 크기 줄이기\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# 학습 후 가장 좋은 모델 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = load_model(checkpoint_path)\n",
    "\n",
    "loss, acc = best_model.evaluate(X_test, y_test)\n",
    "print(\"Best Model Test Accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd681400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
